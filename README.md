Hand Tracking AR UI

This project is an Augmented Reality (AR) Hand Tracking User Interface demo. It uses Python, OpenCV, and MediaPipe to detect your hand via webcam and overlays futuristic UI graphics—radial gauges, HUD elements, and gesture-based controls—directly onto your hand in real time.

->Features

Real-time hand tracking using MediaPipe
AR-style radial and pinch UI overlays
Gesture-based switching (open hand, pinch, fist)
Futuristic HUD graphics: concentric circles, radial ticks, core pattern, numeric overlays
All graphics generated programmatically

->Technologies Used

1 Python 3.8+

2 OpenCV

3 MediaPipe

 ->Numpy

Usage

1 Allow webcam access when prompted.

2 Move your hand in front of the camera to interact with the AR UI overlays.

3 Try different gestures (open hand, pinch, fist) to see UI changes.
